{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, SimpleRNN, Dropout, LSTM, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Passive Agressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"news.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3171\n",
       "1    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_dict = {'REAL': 0, 'FAKE': 1}\n",
    "df['label'] = df['label'].replace(conversion_dict)\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text  label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      1  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      1  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      0  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      1  \n",
       "4  It's primary day in New York and front-runners...      0  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...      1  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...      1  \n",
       "7  A Czech stockbroker who saved more than 650 Je...      0  \n",
       "8  Hillary Clinton and Donald Trump made some ina...      0  \n",
       "9  Iranian negotiators reportedly have made a las...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words vectorize and model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_first,x_test_first,y_train_first,y_test_first=train_test_split(df['text'], df['label'], test_size=0.25, random_state=7, shuffle=True)\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(max_iter=50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_vec_train=tfidf_vectorizer.fit_transform(x_train_first.values.astype('U'))\n",
    "first_vec_test=tfidf_vectorizer.transform(x_test_first.values.astype('U'))\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(first_vec_train,y_train_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.49%\n"
     ]
    }
   ],
   "source": [
    "y_pred=pac.predict(first_vec_test)\n",
    "score=accuracy_score(y_test_first,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[717,  59],\n",
       "       [ 60, 748]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_first,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.83%\n"
     ]
    }
   ],
   "source": [
    "X=tfidf_vectorizer.transform(df['text'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, df['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another way to represent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(max_iter=50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "count_vector_first = vectorizer.fit_transform(x_train_first.values.astype('U'))\n",
    "first_count_test=vectorizer.transform(x_test_first.values.astype('U'))\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(count_vector_first,y_train_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.78%\n"
     ]
    }
   ],
   "source": [
    "y_pred=pac.predict(first_count_test)\n",
    "score=accuracy_score(y_test_first,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[727,  49],\n",
       "       [ 97, 711]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_first,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lurakil/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.58%\n"
     ]
    }
   ],
   "source": [
    "X=vectorizer.transform(df['text'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, df['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true=pd.read_csv('True.csv', nrows=2500)\n",
    "df_true['label']= 0\n",
    "df_true_rep=[df_true['text'][i].replace('WASHINGTON (Reuters) - ','').replace('LONDON (Reuters) - ','').replace('(Reuters) - ','') for i in range(len(df_true['text']))]\n",
    "df_true['text']=df_true_rep\n",
    "df_fake = pd.read_csv(\"Fake.csv\" ,nrows=2500)\n",
    "df_fake['label']= 1\n",
    "df_final=pd.concat([df_true,df_fake])\n",
    "df_final=df_final.drop(['subject','date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>The head of a conservative Republican faction ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>Transgender people will be allowed for the fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>The special counsel investigation of links bet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>Trump campaign adviser George Papadopoulos tol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/President Donald Trump called on the U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White House, Congress prepare for talks on spe...</td>\n",
       "      <td>WEST PALM BEACH, Fla./The White House said on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trump says Russia probe will be fair, but time...</td>\n",
       "      <td>WEST PALM BEACH, Fla President Donald Trump sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Factbox: Trump on Twitter (Dec 29) - Approval ...</td>\n",
       "      <td>The following statements were posted to the ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trump on Twitter (Dec 28) - Global Warming</td>\n",
       "      <td>The following statements were posted to the ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alabama official to certify Senator-elect Jone...</td>\n",
       "      <td>Alabama Secretary of State John Merrill said h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "5  White House, Congress prepare for talks on spe...   \n",
       "6  Trump says Russia probe will be fair, but time...   \n",
       "7  Factbox: Trump on Twitter (Dec 29) - Approval ...   \n",
       "8         Trump on Twitter (Dec 28) - Global Warming   \n",
       "9  Alabama official to certify Senator-elect Jone...   \n",
       "\n",
       "                                                text  label  \n",
       "0  The head of a conservative Republican faction ...      0  \n",
       "1  Transgender people will be allowed for the fir...      0  \n",
       "2  The special counsel investigation of links bet...      0  \n",
       "3  Trump campaign adviser George Papadopoulos tol...      0  \n",
       "4  SEATTLE/President Donald Trump called on the U...      0  \n",
       "5  WEST PALM BEACH, Fla./The White House said on ...      0  \n",
       "6  WEST PALM BEACH, Fla President Donald Trump sa...      0  \n",
       "7  The following statements were posted to the ve...      0  \n",
       "8  The following statements were posted to the ve...      0  \n",
       "9  Alabama Secretary of State John Merrill said h...      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>REPORT: Even Republicans Are ‘Disturbed’ By T...</td>\n",
       "      <td>Donald Trump s days in the White House could b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>Eric Trump Just Asked The Labor Department To...</td>\n",
       "      <td>If any other American company did this, Donald...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>REPORT: Trump Considering Using National Guar...</td>\n",
       "      <td>Donald Trump reportedly wants to use the Natio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>WATCH: Trump Assumes Black Reporter Can Set U...</td>\n",
       "      <td>After claiming that he s  the least racist per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Trump Thinks Rush Limbaugh Is Real News And T...</td>\n",
       "      <td>Rush Limbaugh praised Donald Trump s insanely ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>WATCH: Fox News Host DEFENDS CNN Reporter, Te...</td>\n",
       "      <td>Even Fox News is calling Donald Trump out for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>GOP Senator DESPERATELY Worried About Trump’s...</td>\n",
       "      <td>On Thursday afternoon, the world was treated t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>WATCH: NBC Reporter Calls Trump Out For Lying...</td>\n",
       "      <td>Donald Trump finally held his first solo press...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>Tapper SLAMS Trump For BIZARRE Behavior At ‘W...</td>\n",
       "      <td>There is certainly no love lost between CNN an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>LOL: Putin Is Angry Now Because Trump Gets Mo...</td>\n",
       "      <td>Vladimir Putin is super pissed because Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "2490   REPORT: Even Republicans Are ‘Disturbed’ By T...   \n",
       "2491   Eric Trump Just Asked The Labor Department To...   \n",
       "2492   REPORT: Trump Considering Using National Guar...   \n",
       "2493   WATCH: Trump Assumes Black Reporter Can Set U...   \n",
       "2494   Trump Thinks Rush Limbaugh Is Real News And T...   \n",
       "2495   WATCH: Fox News Host DEFENDS CNN Reporter, Te...   \n",
       "2496   GOP Senator DESPERATELY Worried About Trump’s...   \n",
       "2497   WATCH: NBC Reporter Calls Trump Out For Lying...   \n",
       "2498   Tapper SLAMS Trump For BIZARRE Behavior At ‘W...   \n",
       "2499   LOL: Putin Is Angry Now Because Trump Gets Mo...   \n",
       "\n",
       "                                                   text  label  \n",
       "2490  Donald Trump s days in the White House could b...      1  \n",
       "2491  If any other American company did this, Donald...      1  \n",
       "2492  Donald Trump reportedly wants to use the Natio...      1  \n",
       "2493  After claiming that he s  the least racist per...      1  \n",
       "2494  Rush Limbaugh praised Donald Trump s insanely ...      1  \n",
       "2495  Even Fox News is calling Donald Trump out for ...      1  \n",
       "2496  On Thursday afternoon, the world was treated t...      1  \n",
       "2497  Donald Trump finally held his first solo press...      1  \n",
       "2498  There is certainly no love lost between CNN an...      1  \n",
       "2499  Vladimir Putin is super pissed because Russian...      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model build and words vecrorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_second,x_test_second,y_train_second,y_test_second=train_test_split(df_final['text'], df_final['label'], test_size=0.25)\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(max_iter=50)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_vec_train=tfidf_vectorizer.fit_transform(x_train_second.values.astype('U')) \n",
    "second_vec_test=tfidf_vectorizer.transform(x_test_second.values.astype('U'))\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(second_vec_train, y_train_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.28%\n"
     ]
    }
   ],
   "source": [
    "y_pred=pac.predict(second_vec_test)\n",
    "score=accuracy_score(y_test_second,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[609,   4],\n",
       "       [  5, 632]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_second,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.58%\n"
     ]
    }
   ],
   "source": [
    "X=tfidf_vectorizer.transform(df['text'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, df['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another way to represent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(max_iter=50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "count_vector_second = vectorizer.fit_transform(x_train_second.values.astype('U'))\n",
    "second_count_test=vectorizer.transform(x_test_second.values.astype('U'))\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(count_vector_second,y_train_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.48%\n"
     ]
    }
   ],
   "source": [
    "y_pred=pac.predict(second_count_test)\n",
    "score=accuracy_score(y_test_second,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[608,   5],\n",
       "       [ 14, 623]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_second,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.84%\n"
     ]
    }
   ],
   "source": [
    "X=vectorizer.transform(df_final['text'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, df_final['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state=0)\n",
    "RFC.fit(first_vec_train, y_train_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.59%\n"
     ]
    }
   ],
   "source": [
    "y_pred=RFC.predict(first_vec_test)\n",
    "score=accuracy_score(y_test_first,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[715,  61],\n",
       "       [ 88, 720]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_first,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.47%\n"
     ]
    }
   ],
   "source": [
    "X=tfidf_vectorizer.transform(df['text'].values.astype('U'))\n",
    "scores = cross_val_score(RFC, X, df['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another way to represent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state=0)\n",
    "RFC.fit(count_vector_first, y_train_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n"
     ]
    }
   ],
   "source": [
    "y_pred=RFC.predict(first_count_test)\n",
    "score=accuracy_score(y_test_first,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[674, 102],\n",
       "       [ 90, 718]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_first,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.79%\n"
     ]
    }
   ],
   "source": [
    "X=vectorizer.transform(df['text'].values.astype('U'))\n",
    "scores = cross_val_score(RFC, X, df['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state=0)\n",
    "RFC.fit(second_vec_train, y_train_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.68%\n"
     ]
    }
   ],
   "source": [
    "y_pred=RFC.predict(second_vec_test)\n",
    "score=accuracy_score(y_test_second,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[610,   3],\n",
       "       [  1, 636]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_second,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.28%\n"
     ]
    }
   ],
   "source": [
    "X=tfidf_vectorizer.transform(df_final['text'].values.astype('U'))\n",
    "scores = cross_val_score(RFC, X, df_final['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another way to represent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state=0)\n",
    "RFC.fit(count_vector_second, y_train_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.6%\n"
     ]
    }
   ],
   "source": [
    "y_pred=RFC.predict(second_count_test)\n",
    "score=accuracy_score(y_test_second,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[611,   2],\n",
       "       [  3, 634]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_second,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.3%\n"
     ]
    }
   ],
   "source": [
    "X=vectorizer.transform(df_final['text'].values.astype('U'))\n",
    "scores = cross_val_score(RFC, X, df_final['label'].values, cv=5)\n",
    "print(f'Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=.8, random_state=11)\n",
    "df_test = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['label'].values\n",
    "y_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['text'].values\n",
    "X_test = df_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87596\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_dict = tokenizer.index_word\n",
    "print(len(word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_seq, maxlen=512, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=512, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "laenge_pads = 512\n",
    "vocab_size = len(word_dict)\n",
    "output_dim=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 512, 64)           5606208   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 5,705,153\n",
      "Trainable params: 5,705,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=vocab_size+1, output_dim=output_dim, input_length=laenge_pads))\n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(LSTM(128))\n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 48s 603ms/step - loss: 0.6370 - accuracy: 0.6667 - val_loss: 0.6071 - val_accuracy: 0.7443\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 47s 593ms/step - loss: 0.5110 - accuracy: 0.7747 - val_loss: 0.4709 - val_accuracy: 0.7845\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 48s 603ms/step - loss: 0.3780 - accuracy: 0.8285 - val_loss: 0.4367 - val_accuracy: 0.8122\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 49s 611ms/step - loss: 0.3712 - accuracy: 0.8512 - val_loss: 0.5432 - val_accuracy: 0.7348\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 50s 622ms/step - loss: 0.3885 - accuracy: 0.8236 - val_loss: 0.5507 - val_accuracy: 0.7096\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 49s 616ms/step - loss: 0.3556 - accuracy: 0.8408 - val_loss: 0.5127 - val_accuracy: 0.7593\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 48s 604ms/step - loss: 0.3027 - accuracy: 0.8613 - val_loss: 0.5150 - val_accuracy: 0.8169\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 48s 602ms/step - loss: 0.3373 - accuracy: 0.8421 - val_loss: 0.4939 - val_accuracy: 0.7822\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 49s 609ms/step - loss: 0.3099 - accuracy: 0.8309 - val_loss: 0.4935 - val_accuracy: 0.7798\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 49s 609ms/step - loss: 0.2929 - accuracy: 0.8609 - val_loss: 0.6301 - val_accuracy: 0.7182\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 49s 609ms/step - loss: 0.3539 - accuracy: 0.8356 - val_loss: 0.5042 - val_accuracy: 0.7648\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 49s 609ms/step - loss: 0.2361 - accuracy: 0.8625 - val_loss: 0.4090 - val_accuracy: 0.7853\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 49s 616ms/step - loss: 0.2128 - accuracy: 0.8759 - val_loss: 0.4164 - val_accuracy: 0.8003\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 50s 620ms/step - loss: 0.2044 - accuracy: 0.8852 - val_loss: 0.4241 - val_accuracy: 0.8019\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 50s 623ms/step - loss: 0.1995 - accuracy: 0.8927 - val_loss: 0.5511 - val_accuracy: 0.8493\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 50s 630ms/step - loss: 0.2080 - accuracy: 0.9023 - val_loss: 0.4796 - val_accuracy: 0.8153\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 50s 623ms/step - loss: 0.1937 - accuracy: 0.9071 - val_loss: 0.4820 - val_accuracy: 0.8169\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 50s 630ms/step - loss: 0.2052 - accuracy: 0.9140 - val_loss: 0.4559 - val_accuracy: 0.8137\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 50s 629ms/step - loss: 0.1938 - accuracy: 0.9075 - val_loss: 0.5538 - val_accuracy: 0.8074\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 51s 632ms/step - loss: 0.1948 - accuracy: 0.9019 - val_loss: 0.4820 - val_accuracy: 0.8248\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 51s 635ms/step - loss: 0.1834 - accuracy: 0.9203 - val_loss: 0.4890 - val_accuracy: 0.8335\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 51s 636ms/step - loss: 0.1896 - accuracy: 0.9102 - val_loss: 0.4795 - val_accuracy: 0.8303\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 51s 640ms/step - loss: 0.1800 - accuracy: 0.9179 - val_loss: 0.5054 - val_accuracy: 0.8350\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 51s 642ms/step - loss: 0.1721 - accuracy: 0.9236 - val_loss: 0.6079 - val_accuracy: 0.8185\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 51s 640ms/step - loss: 0.1699 - accuracy: 0.9258 - val_loss: 0.5641 - val_accuracy: 0.8453\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 51s 639ms/step - loss: 0.1846 - accuracy: 0.9205 - val_loss: 0.6113 - val_accuracy: 0.7530\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 52s 644ms/step - loss: 0.1908 - accuracy: 0.9203 - val_loss: 0.4734 - val_accuracy: 0.8106\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 52s 645ms/step - loss: 0.1918 - accuracy: 0.9179 - val_loss: 0.4753 - val_accuracy: 0.8256\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 51s 641ms/step - loss: 0.1749 - accuracy: 0.9144 - val_loss: 0.5504 - val_accuracy: 0.8327\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 51s 641ms/step - loss: 0.2033 - accuracy: 0.9199 - val_loss: 0.5176 - val_accuracy: 0.8382\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 52s 647ms/step - loss: 0.2868 - accuracy: 0.8601 - val_loss: 0.5973 - val_accuracy: 0.7987\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 52s 653ms/step - loss: 0.1764 - accuracy: 0.9254 - val_loss: 0.5001 - val_accuracy: 0.8303\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 52s 650ms/step - loss: 0.1399 - accuracy: 0.9483 - val_loss: 0.5267 - val_accuracy: 0.8319\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 51s 638ms/step - loss: 0.1205 - accuracy: 0.9615 - val_loss: 0.4915 - val_accuracy: 0.8445\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 52s 652ms/step - loss: 0.1070 - accuracy: 0.9686 - val_loss: 0.4802 - val_accuracy: 0.8571\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0996 - accuracy: 0.9743 - val_loss: 0.5280 - val_accuracy: 0.8548\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 52s 652ms/step - loss: 0.1287 - accuracy: 0.9532 - val_loss: 0.5164 - val_accuracy: 0.8335\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 52s 648ms/step - loss: 0.0874 - accuracy: 0.9759 - val_loss: 0.5315 - val_accuracy: 0.8556\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 52s 646ms/step - loss: 0.0872 - accuracy: 0.9759 - val_loss: 0.5242 - val_accuracy: 0.8343\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 52s 648ms/step - loss: 0.0894 - accuracy: 0.9765 - val_loss: 0.5402 - val_accuracy: 0.8579\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 52s 648ms/step - loss: 0.0812 - accuracy: 0.9797 - val_loss: 0.6408 - val_accuracy: 0.8540\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 52s 649ms/step - loss: 0.1075 - accuracy: 0.9663 - val_loss: 0.5563 - val_accuracy: 0.8398\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0809 - accuracy: 0.9759 - val_loss: 0.5998 - val_accuracy: 0.8374\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0783 - accuracy: 0.9801 - val_loss: 0.5958 - val_accuracy: 0.8461\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.2312 - accuracy: 0.9116 - val_loss: 0.4422 - val_accuracy: 0.8524\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0751 - accuracy: 0.9828 - val_loss: 0.5103 - val_accuracy: 0.8556\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0730 - accuracy: 0.9834 - val_loss: 0.5306 - val_accuracy: 0.8603\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0721 - accuracy: 0.9844 - val_loss: 0.4989 - val_accuracy: 0.8619\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0934 - accuracy: 0.9789 - val_loss: 0.4870 - val_accuracy: 0.8682\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 52s 656ms/step - loss: 0.0613 - accuracy: 0.9860 - val_loss: 0.5085 - val_accuracy: 0.8524\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0563 - accuracy: 0.9884 - val_loss: 0.5554 - val_accuracy: 0.8611\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 53s 656ms/step - loss: 0.0511 - accuracy: 0.9891 - val_loss: 0.6063 - val_accuracy: 0.8595\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0538 - accuracy: 0.9882 - val_loss: 0.5589 - val_accuracy: 0.8579\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 53s 656ms/step - loss: 0.0522 - accuracy: 0.9893 - val_loss: 0.5553 - val_accuracy: 0.8595\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0518 - accuracy: 0.9893 - val_loss: 0.5518 - val_accuracy: 0.8658\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0506 - accuracy: 0.9893 - val_loss: 0.5516 - val_accuracy: 0.8666\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0498 - accuracy: 0.9893 - val_loss: 0.5517 - val_accuracy: 0.8674\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0517 - accuracy: 0.9893 - val_loss: 0.5529 - val_accuracy: 0.8706\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0477 - accuracy: 0.9895 - val_loss: 0.5818 - val_accuracy: 0.8690\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0571 - accuracy: 0.9876 - val_loss: 0.5770 - val_accuracy: 0.8556\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 53s 656ms/step - loss: 0.0754 - accuracy: 0.9826 - val_loss: 0.5472 - val_accuracy: 0.8343\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 52s 656ms/step - loss: 0.0559 - accuracy: 0.9890 - val_loss: 0.5737 - val_accuracy: 0.8619\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 52s 656ms/step - loss: 0.0632 - accuracy: 0.9858 - val_loss: 0.6331 - val_accuracy: 0.8548\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.2538 - accuracy: 0.9067 - val_loss: 0.4995 - val_accuracy: 0.8500\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 54s 669ms/step - loss: 0.0645 - accuracy: 0.9854 - val_loss: 0.5469 - val_accuracy: 0.8564\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0558 - accuracy: 0.9882 - val_loss: 0.5638 - val_accuracy: 0.8595\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0513 - accuracy: 0.9890 - val_loss: 0.5715 - val_accuracy: 0.8587\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0550 - accuracy: 0.9882 - val_loss: 0.5689 - val_accuracy: 0.8635\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0530 - accuracy: 0.9888 - val_loss: 0.5556 - val_accuracy: 0.8642\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0521 - accuracy: 0.9888 - val_loss: 0.5857 - val_accuracy: 0.8627\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 52s 656ms/step - loss: 0.0491 - accuracy: 0.9893 - val_loss: 0.5859 - val_accuracy: 0.8469\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 52s 656ms/step - loss: 0.1811 - accuracy: 0.9465 - val_loss: 0.7832 - val_accuracy: 0.7758\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 54s 678ms/step - loss: 0.0872 - accuracy: 0.9785 - val_loss: 0.5126 - val_accuracy: 0.8548\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 54s 673ms/step - loss: 0.0573 - accuracy: 0.9880 - val_loss: 0.5055 - val_accuracy: 0.8642\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0444 - accuracy: 0.9913 - val_loss: 0.5291 - val_accuracy: 0.8611\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 53s 663ms/step - loss: 0.0410 - accuracy: 0.9921 - val_loss: 0.5611 - val_accuracy: 0.8650\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0391 - accuracy: 0.9925 - val_loss: 0.5686 - val_accuracy: 0.8627\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0389 - accuracy: 0.9925 - val_loss: 0.5542 - val_accuracy: 0.8690\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0387 - accuracy: 0.9925 - val_loss: 0.5632 - val_accuracy: 0.8706\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 52s 653ms/step - loss: 0.0370 - accuracy: 0.9925 - val_loss: 0.5543 - val_accuracy: 0.8745\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 52s 651ms/step - loss: 0.0397 - accuracy: 0.9925 - val_loss: 0.5620 - val_accuracy: 0.8737\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0400 - accuracy: 0.9923 - val_loss: 0.5489 - val_accuracy: 0.8777\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0377 - accuracy: 0.9927 - val_loss: 0.5708 - val_accuracy: 0.8777\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0375 - accuracy: 0.9929 - val_loss: 0.5630 - val_accuracy: 0.8785\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0362 - accuracy: 0.9929 - val_loss: 0.5693 - val_accuracy: 0.8769\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0359 - accuracy: 0.9929 - val_loss: 0.5659 - val_accuracy: 0.8769\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0388 - accuracy: 0.9923 - val_loss: 0.5973 - val_accuracy: 0.8508\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0412 - accuracy: 0.9917 - val_loss: 0.5746 - val_accuracy: 0.8713\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0392 - accuracy: 0.9923 - val_loss: 0.5641 - val_accuracy: 0.8737\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0384 - accuracy: 0.9925 - val_loss: 0.7337 - val_accuracy: 0.8564\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0415 - accuracy: 0.9921 - val_loss: 0.6183 - val_accuracy: 0.8674\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 53s 656ms/step - loss: 0.0344 - accuracy: 0.9933 - val_loss: 0.6309 - val_accuracy: 0.8642\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0354 - accuracy: 0.9933 - val_loss: 0.6440 - val_accuracy: 0.8650\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0352 - accuracy: 0.9933 - val_loss: 0.6530 - val_accuracy: 0.8658\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 53s 656ms/step - loss: 0.0344 - accuracy: 0.9933 - val_loss: 0.6446 - val_accuracy: 0.8658\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 0.6539 - val_accuracy: 0.8666\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0350 - accuracy: 0.9933 - val_loss: 0.6576 - val_accuracy: 0.8658\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 53s 669ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 0.6483 - val_accuracy: 0.8666\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0340 - accuracy: 0.9933 - val_loss: 0.6634 - val_accuracy: 0.8674\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 53s 666ms/step - loss: 0.0341 - accuracy: 0.9933 - val_loss: 0.6281 - val_accuracy: 0.8721\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0344 - accuracy: 0.9933 - val_loss: 0.6350 - val_accuracy: 0.8698\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0351 - accuracy: 0.9933 - val_loss: 0.6558 - val_accuracy: 0.8690\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0476 - accuracy: 0.9897 - val_loss: 0.6265 - val_accuracy: 0.8737\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 52s 646ms/step - loss: 0.1631 - accuracy: 0.9599 - val_loss: 0.9348 - val_accuracy: 0.7159\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 53s 661ms/step - loss: 0.0868 - accuracy: 0.9801 - val_loss: 0.5717 - val_accuracy: 0.8524\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 53s 661ms/step - loss: 0.0394 - accuracy: 0.9931 - val_loss: 0.5966 - val_accuracy: 0.8556\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0289 - accuracy: 0.9951 - val_loss: 0.6220 - val_accuracy: 0.8556\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0288 - accuracy: 0.9951 - val_loss: 0.6166 - val_accuracy: 0.8635\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 53s 661ms/step - loss: 0.0360 - accuracy: 0.9929 - val_loss: 0.6147 - val_accuracy: 0.8627\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0270 - accuracy: 0.9953 - val_loss: 0.6193 - val_accuracy: 0.8595\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 53s 661ms/step - loss: 0.0233 - accuracy: 0.9963 - val_loss: 0.6231 - val_accuracy: 0.8611\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0237 - accuracy: 0.9961 - val_loss: 0.6286 - val_accuracy: 0.8635\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.6343 - val_accuracy: 0.8650\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0219 - accuracy: 0.9963 - val_loss: 0.6634 - val_accuracy: 0.8635\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.6489 - val_accuracy: 0.8627\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 53s 661ms/step - loss: 0.0230 - accuracy: 0.9963 - val_loss: 0.6794 - val_accuracy: 0.8635\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0227 - accuracy: 0.9963 - val_loss: 0.6369 - val_accuracy: 0.8658\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0234 - accuracy: 0.9961 - val_loss: 0.6543 - val_accuracy: 0.8658\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 53s 664ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.6722 - val_accuracy: 0.8658\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 53s 661ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.6647 - val_accuracy: 0.8658\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 53s 663ms/step - loss: 0.0224 - accuracy: 0.9963 - val_loss: 0.6815 - val_accuracy: 0.8674\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 53s 660ms/step - loss: 0.0224 - accuracy: 0.9963 - val_loss: 0.6804 - val_accuracy: 0.8650\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 54s 672ms/step - loss: 0.0219 - accuracy: 0.9963 - val_loss: 0.6904 - val_accuracy: 0.8666\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 54s 671ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.6873 - val_accuracy: 0.8658\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0305 - accuracy: 0.9939 - val_loss: 0.6111 - val_accuracy: 0.8469\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0270 - accuracy: 0.9957 - val_loss: 0.6686 - val_accuracy: 0.8540\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 54s 672ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.6952 - val_accuracy: 0.8587\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 53s 658ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.6986 - val_accuracy: 0.8603\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 52s 655ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.7131 - val_accuracy: 0.8603\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0219 - accuracy: 0.9963 - val_loss: 0.6838 - val_accuracy: 0.8587\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 53s 663ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.7177 - val_accuracy: 0.8595\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.6843 - val_accuracy: 0.8603\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0222 - accuracy: 0.9963 - val_loss: 0.6839 - val_accuracy: 0.8603\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.7044 - val_accuracy: 0.8603\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.7009 - val_accuracy: 0.8619\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 0.7265 - val_accuracy: 0.8619\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.7365 - val_accuracy: 0.8611\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.7292 - val_accuracy: 0.8619\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.7249 - val_accuracy: 0.8650\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.7513 - val_accuracy: 0.8627\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0237 - accuracy: 0.9963 - val_loss: 0.7341 - val_accuracy: 0.8658\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0214 - accuracy: 0.9963 - val_loss: 0.7075 - val_accuracy: 0.8650\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 53s 666ms/step - loss: 0.0218 - accuracy: 0.9963 - val_loss: 0.7578 - val_accuracy: 0.8619\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 53s 665ms/step - loss: 0.0238 - accuracy: 0.9961 - val_loss: 0.7480 - val_accuracy: 0.8595\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 53s 664ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.7233 - val_accuracy: 0.8635\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 53s 664ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.7386 - val_accuracy: 0.8619\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 54s 673ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.7452 - val_accuracy: 0.8619\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 0.7423 - val_accuracy: 0.8595\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 0.7465 - val_accuracy: 0.8595\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 54s 669ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 0.7616 - val_accuracy: 0.8619\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 52s 650ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.7648 - val_accuracy: 0.8619\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0218 - accuracy: 0.9963 - val_loss: 0.7274 - val_accuracy: 0.8635\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 54s 672ms/step - loss: 0.0224 - accuracy: 0.9963 - val_loss: 0.7625 - val_accuracy: 0.8619\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 54s 674ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.7546 - val_accuracy: 0.8635\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 54s 669ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 0.7590 - val_accuracy: 0.8635\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0218 - accuracy: 0.9963 - val_loss: 0.7454 - val_accuracy: 0.8642\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 54s 671ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.7657 - val_accuracy: 0.8635\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0218 - accuracy: 0.9963 - val_loss: 0.7724 - val_accuracy: 0.8642\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 54s 672ms/step - loss: 0.0224 - accuracy: 0.9963 - val_loss: 0.7805 - val_accuracy: 0.8642\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 54s 672ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.7789 - val_accuracy: 0.8674\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 52s 648ms/step - loss: 0.0217 - accuracy: 0.9963 - val_loss: 0.7490 - val_accuracy: 0.8706\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 53s 661ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 0.7760 - val_accuracy: 0.8674\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 53s 665ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.7820 - val_accuracy: 0.8674\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 54s 669ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.7630 - val_accuracy: 0.8682\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0222 - accuracy: 0.9963 - val_loss: 0.7557 - val_accuracy: 0.8690\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0502 - accuracy: 0.9890 - val_loss: 0.7659 - val_accuracy: 0.8272\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0485 - accuracy: 0.9893 - val_loss: 0.6459 - val_accuracy: 0.8650\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0251 - accuracy: 0.9957 - val_loss: 0.6335 - val_accuracy: 0.8611\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0287 - accuracy: 0.9947 - val_loss: 0.6693 - val_accuracy: 0.8587\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0217 - accuracy: 0.9963 - val_loss: 0.6312 - val_accuracy: 0.8706\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0198 - accuracy: 0.9966 - val_loss: 0.6564 - val_accuracy: 0.8650\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.6646 - val_accuracy: 0.8682\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0181 - accuracy: 0.9968 - val_loss: 0.6726 - val_accuracy: 0.8698\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 54s 672ms/step - loss: 0.0187 - accuracy: 0.9968 - val_loss: 0.6800 - val_accuracy: 0.8690\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 54s 670ms/step - loss: 0.0190 - accuracy: 0.9968 - val_loss: 0.6870 - val_accuracy: 0.8721\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 53s 662ms/step - loss: 0.0185 - accuracy: 0.9968 - val_loss: 0.6814 - val_accuracy: 0.8745\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 53s 657ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.6901 - val_accuracy: 0.8761\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 53s 659ms/step - loss: 0.0177 - accuracy: 0.9968 - val_loss: 0.6893 - val_accuracy: 0.8745\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 53s 666ms/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.7109 - val_accuracy: 0.8761\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.7078 - val_accuracy: 0.8761\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 53s 666ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.7087 - val_accuracy: 0.8769\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0182 - accuracy: 0.9968 - val_loss: 0.7078 - val_accuracy: 0.8777\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 54s 669ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.7116 - val_accuracy: 0.8777\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 53s 665ms/step - loss: 0.0191 - accuracy: 0.9968 - val_loss: 0.7173 - val_accuracy: 0.8769\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0197 - accuracy: 0.9968 - val_loss: 0.7199 - val_accuracy: 0.8777\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 0.7243 - val_accuracy: 0.8745\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 53s 666ms/step - loss: 0.0182 - accuracy: 0.9968 - val_loss: 0.7280 - val_accuracy: 0.8769\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 53s 664ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 0.7267 - val_accuracy: 0.8769\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 0.7384 - val_accuracy: 0.8792\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 54s 671ms/step - loss: 0.0189 - accuracy: 0.9968 - val_loss: 0.7411 - val_accuracy: 0.8785\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0185 - accuracy: 0.9968 - val_loss: 0.7549 - val_accuracy: 0.8792\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 53s 666ms/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.7486 - val_accuracy: 0.8777\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 53s 665ms/step - loss: 0.0183 - accuracy: 0.9968 - val_loss: 0.7558 - val_accuracy: 0.8792\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 53s 665ms/step - loss: 0.0182 - accuracy: 0.9968 - val_loss: 0.7495 - val_accuracy: 0.8800\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 53s 665ms/step - loss: 0.0187 - accuracy: 0.9968 - val_loss: 0.6888 - val_accuracy: 0.8785\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 53s 666ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.7106 - val_accuracy: 0.8777\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 54s 676ms/step - loss: 0.0187 - accuracy: 0.9968 - val_loss: 0.7303 - val_accuracy: 0.8800\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.7254 - val_accuracy: 0.8792\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 53s 668ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.7302 - val_accuracy: 0.8816\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 53s 667ms/step - loss: 0.0189 - accuracy: 0.9968 - val_loss: 0.7324 - val_accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit(X_train_pad, y_train, epochs=200, batch_size=64, \n",
    "                        validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.0%\n"
     ]
    }
   ],
   "source": [
    "pred_y = lstm_model.predict_classes(X_test_pad)\n",
    "score=accuracy_score(y_test,pred_y)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[523,  88],\n",
       "       [ 64, 592]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 512, 64)           5606208   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 512, 64)           8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 512, 64)           8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,631,041\n",
      "Trainable params: 5,631,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(input_dim = vocab_size + 1, output_dim = output_dim, input_length = laenge_pads))\n",
    "rnn_model.add(SimpleRNN(output_dim, return_sequences=True, kernel_constraint=maxnorm(50)))\n",
    "rnn_model.add(Dropout(0.1))\n",
    "rnn_model.add(SimpleRNN(output_dim, return_sequences=True, kernel_constraint=maxnorm(50)))\n",
    "rnn_model.add(Dropout(0.1))\n",
    "rnn_model.add(SimpleRNN(output_dim))\n",
    "rnn_model.add(Dropout(0.1))\n",
    "rnn_model.add(Dense(1,activation='sigmoid'))\n",
    "rnn_model.compile(optimizer='sgd', loss='mse',  metrics=['accuracy'])\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 30s 370ms/step - loss: 0.2408 - accuracy: 0.6166 - val_loss: 0.2265 - val_accuracy: 0.6440\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2357 - accuracy: 0.6298 - val_loss: 0.2262 - val_accuracy: 0.6464\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 27s 342ms/step - loss: 0.2335 - accuracy: 0.6306 - val_loss: 0.2227 - val_accuracy: 0.6527\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2310 - accuracy: 0.6389 - val_loss: 0.2255 - val_accuracy: 0.6511\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.2294 - accuracy: 0.6405 - val_loss: 0.2212 - val_accuracy: 0.6535\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 29s 357ms/step - loss: 0.2265 - accuracy: 0.6452 - val_loss: 0.2201 - val_accuracy: 0.6606\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 29s 358ms/step - loss: 0.2223 - accuracy: 0.6527 - val_loss: 0.2194 - val_accuracy: 0.6535\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.2205 - accuracy: 0.6559 - val_loss: 0.2207 - val_accuracy: 0.6575\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 29s 361ms/step - loss: 0.2200 - accuracy: 0.6579 - val_loss: 0.2212 - val_accuracy: 0.6488\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.2192 - accuracy: 0.6577 - val_loss: 0.2226 - val_accuracy: 0.6598\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 29s 359ms/step - loss: 0.2160 - accuracy: 0.6650 - val_loss: 0.2191 - val_accuracy: 0.6669\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 29s 362ms/step - loss: 0.2130 - accuracy: 0.6697 - val_loss: 0.2202 - val_accuracy: 0.6606\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 29s 356ms/step - loss: 0.2119 - accuracy: 0.6752 - val_loss: 0.2182 - val_accuracy: 0.6622\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.2068 - accuracy: 0.6833 - val_loss: 0.2199 - val_accuracy: 0.6646\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.2045 - accuracy: 0.6924 - val_loss: 0.2189 - val_accuracy: 0.6701\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.2023 - accuracy: 0.6949 - val_loss: 0.2176 - val_accuracy: 0.6796\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1999 - accuracy: 0.7038 - val_loss: 0.2181 - val_accuracy: 0.6748\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.1975 - accuracy: 0.7092 - val_loss: 0.2161 - val_accuracy: 0.6796\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.1979 - accuracy: 0.7094 - val_loss: 0.2289 - val_accuracy: 0.6338\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1943 - accuracy: 0.7157 - val_loss: 0.2213 - val_accuracy: 0.6646\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1901 - accuracy: 0.7247 - val_loss: 0.2179 - val_accuracy: 0.6646\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1852 - accuracy: 0.7328 - val_loss: 0.2170 - val_accuracy: 0.6701\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.1828 - accuracy: 0.7374 - val_loss: 0.2198 - val_accuracy: 0.6725\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1788 - accuracy: 0.7463 - val_loss: 0.2170 - val_accuracy: 0.6709\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 29s 357ms/step - loss: 0.1748 - accuracy: 0.7520 - val_loss: 0.2163 - val_accuracy: 0.6748\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1711 - accuracy: 0.7601 - val_loss: 0.2374 - val_accuracy: 0.6298\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1685 - accuracy: 0.7638 - val_loss: 0.2192 - val_accuracy: 0.6740\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 29s 362ms/step - loss: 0.1656 - accuracy: 0.7672 - val_loss: 0.2420 - val_accuracy: 0.6606\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.1600 - accuracy: 0.7753 - val_loss: 0.2199 - val_accuracy: 0.6756\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 29s 356ms/step - loss: 0.1556 - accuracy: 0.7873 - val_loss: 0.2846 - val_accuracy: 0.5501\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 29s 357ms/step - loss: 0.2331 - accuracy: 0.6367 - val_loss: 0.2202 - val_accuracy: 0.6819\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.2326 - accuracy: 0.6263 - val_loss: 0.2182 - val_accuracy: 0.6717\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.2312 - accuracy: 0.6318 - val_loss: 0.2261 - val_accuracy: 0.6575\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.2305 - accuracy: 0.6363 - val_loss: 0.2191 - val_accuracy: 0.6480\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.2305 - accuracy: 0.6361 - val_loss: 0.2228 - val_accuracy: 0.6472\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.2257 - accuracy: 0.6492 - val_loss: 0.2190 - val_accuracy: 0.6661\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.2264 - accuracy: 0.6482 - val_loss: 0.2178 - val_accuracy: 0.6559\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 28s 355ms/step - loss: 0.2296 - accuracy: 0.6328 - val_loss: 0.2340 - val_accuracy: 0.5848\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2437 - accuracy: 0.5918 - val_loss: 0.2191 - val_accuracy: 0.6480\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2280 - accuracy: 0.6427 - val_loss: 0.2165 - val_accuracy: 0.6551\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2283 - accuracy: 0.6464 - val_loss: 0.2157 - val_accuracy: 0.6575\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2313 - accuracy: 0.6314 - val_loss: 0.2375 - val_accuracy: 0.6440\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2390 - accuracy: 0.5961 - val_loss: 0.2181 - val_accuracy: 0.6511\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 28s 353ms/step - loss: 0.2317 - accuracy: 0.6328 - val_loss: 0.2150 - val_accuracy: 0.6630\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2276 - accuracy: 0.6427 - val_loss: 0.2187 - val_accuracy: 0.6496\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2251 - accuracy: 0.6531 - val_loss: 0.2118 - val_accuracy: 0.6859\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 28s 353ms/step - loss: 0.2223 - accuracy: 0.6581 - val_loss: 0.2240 - val_accuracy: 0.6567\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2170 - accuracy: 0.6626 - val_loss: 0.2070 - val_accuracy: 0.6906\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 29s 357ms/step - loss: 0.2139 - accuracy: 0.6697 - val_loss: 0.2059 - val_accuracy: 0.6953\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 28s 356ms/step - loss: 0.2144 - accuracy: 0.6782 - val_loss: 0.2158 - val_accuracy: 0.6764\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2109 - accuracy: 0.6792 - val_loss: 0.2157 - val_accuracy: 0.6843\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2100 - accuracy: 0.6857 - val_loss: 0.1987 - val_accuracy: 0.7174\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 27s 340ms/step - loss: 0.2079 - accuracy: 0.6880 - val_loss: 0.2183 - val_accuracy: 0.6464\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.2052 - accuracy: 0.6894 - val_loss: 0.2164 - val_accuracy: 0.6527\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2163 - accuracy: 0.6640 - val_loss: 0.2029 - val_accuracy: 0.6961\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2094 - accuracy: 0.6827 - val_loss: 0.2213 - val_accuracy: 0.6780\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2075 - accuracy: 0.6837 - val_loss: 0.2017 - val_accuracy: 0.7174\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2047 - accuracy: 0.6902 - val_loss: 0.1941 - val_accuracy: 0.7088\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2017 - accuracy: 0.6981 - val_loss: 0.1908 - val_accuracy: 0.7245\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2012 - accuracy: 0.6967 - val_loss: 0.2621 - val_accuracy: 0.6519\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.1991 - accuracy: 0.7078 - val_loss: 0.2308 - val_accuracy: 0.6756\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.1962 - accuracy: 0.7097 - val_loss: 0.1893 - val_accuracy: 0.7238\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.1969 - accuracy: 0.7111 - val_loss: 0.2034 - val_accuracy: 0.6851\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 28s 345ms/step - loss: 0.1956 - accuracy: 0.7143 - val_loss: 0.1876 - val_accuracy: 0.7238\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.1950 - accuracy: 0.7125 - val_loss: 0.1966 - val_accuracy: 0.7206\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.1881 - accuracy: 0.7303 - val_loss: 0.2727 - val_accuracy: 0.5659\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.1842 - accuracy: 0.7342 - val_loss: 0.1972 - val_accuracy: 0.7206\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.2363 - accuracy: 0.5813 - val_loss: 0.2480 - val_accuracy: 0.6259\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.2612 - accuracy: 0.5073 - val_loss: 0.2537 - val_accuracy: 0.5075\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2569 - accuracy: 0.5266 - val_loss: 0.2404 - val_accuracy: 0.6393\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 28s 345ms/step - loss: 0.2522 - accuracy: 0.5391 - val_loss: 0.2294 - val_accuracy: 0.6527\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2479 - accuracy: 0.5744 - val_loss: 0.2570 - val_accuracy: 0.4491\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2616 - accuracy: 0.5041 - val_loss: 0.2540 - val_accuracy: 0.5383\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2591 - accuracy: 0.5099 - val_loss: 0.2525 - val_accuracy: 0.5288\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 28s 346ms/step - loss: 0.2578 - accuracy: 0.5101 - val_loss: 0.2516 - val_accuracy: 0.5272\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 28s 345ms/step - loss: 0.2573 - accuracy: 0.5207 - val_loss: 0.2519 - val_accuracy: 0.4546\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 28s 345ms/step - loss: 0.2572 - accuracy: 0.5059 - val_loss: 0.2500 - val_accuracy: 0.5422\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 28s 345ms/step - loss: 0.2548 - accuracy: 0.5176 - val_loss: 0.2498 - val_accuracy: 0.5351\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2543 - accuracy: 0.5225 - val_loss: 0.2571 - val_accuracy: 0.4822\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 28s 345ms/step - loss: 0.2569 - accuracy: 0.5156 - val_loss: 0.2500 - val_accuracy: 0.4665\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2563 - accuracy: 0.5087 - val_loss: 0.2486 - val_accuracy: 0.5517\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2560 - accuracy: 0.5075 - val_loss: 0.2484 - val_accuracy: 0.5454\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2544 - accuracy: 0.5221 - val_loss: 0.2499 - val_accuracy: 0.5351\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2555 - accuracy: 0.5105 - val_loss: 0.2483 - val_accuracy: 0.5446\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 28s 345ms/step - loss: 0.2522 - accuracy: 0.5292 - val_loss: 0.2481 - val_accuracy: 0.5446\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2514 - accuracy: 0.5247 - val_loss: 0.2475 - val_accuracy: 0.5549\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2521 - accuracy: 0.5288 - val_loss: 0.2473 - val_accuracy: 0.5564\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 28s 352ms/step - loss: 0.2518 - accuracy: 0.5251 - val_loss: 0.2474 - val_accuracy: 0.5525\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2529 - accuracy: 0.5201 - val_loss: 0.2486 - val_accuracy: 0.5438\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 28s 352ms/step - loss: 0.2528 - accuracy: 0.5268 - val_loss: 0.2472 - val_accuracy: 0.5549\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2514 - accuracy: 0.5245 - val_loss: 0.2471 - val_accuracy: 0.5549\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 28s 353ms/step - loss: 0.2529 - accuracy: 0.5148 - val_loss: 0.2473 - val_accuracy: 0.5517\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2526 - accuracy: 0.5292 - val_loss: 0.2467 - val_accuracy: 0.5541\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 28s 353ms/step - loss: 0.2510 - accuracy: 0.5298 - val_loss: 0.2464 - val_accuracy: 0.5596\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2518 - accuracy: 0.5290 - val_loss: 0.2465 - val_accuracy: 0.5525\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 29s 357ms/step - loss: 0.2510 - accuracy: 0.5253 - val_loss: 0.2470 - val_accuracy: 0.5564\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2512 - accuracy: 0.5239 - val_loss: 0.2503 - val_accuracy: 0.5462\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2503 - accuracy: 0.5335 - val_loss: 0.2475 - val_accuracy: 0.5556\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 28s 352ms/step - loss: 0.2503 - accuracy: 0.5404 - val_loss: 0.2458 - val_accuracy: 0.5541\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 28s 352ms/step - loss: 0.2526 - accuracy: 0.5184 - val_loss: 0.2507 - val_accuracy: 0.5478\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 28s 353ms/step - loss: 0.2506 - accuracy: 0.5320 - val_loss: 0.2456 - val_accuracy: 0.5541\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2493 - accuracy: 0.5339 - val_loss: 0.2458 - val_accuracy: 0.5556\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2508 - accuracy: 0.5314 - val_loss: 0.2452 - val_accuracy: 0.5580\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2490 - accuracy: 0.5341 - val_loss: 0.2453 - val_accuracy: 0.5572\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2504 - accuracy: 0.5349 - val_loss: 0.2451 - val_accuracy: 0.5580\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 28s 352ms/step - loss: 0.2497 - accuracy: 0.5266 - val_loss: 0.2448 - val_accuracy: 0.5612\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 28s 352ms/step - loss: 0.2494 - accuracy: 0.5389 - val_loss: 0.2452 - val_accuracy: 0.5549\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2506 - accuracy: 0.5286 - val_loss: 0.2447 - val_accuracy: 0.5659\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2494 - accuracy: 0.5294 - val_loss: 0.2445 - val_accuracy: 0.5643\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2497 - accuracy: 0.5296 - val_loss: 0.2442 - val_accuracy: 0.5627\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2484 - accuracy: 0.5351 - val_loss: 0.2445 - val_accuracy: 0.5643\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2480 - accuracy: 0.5361 - val_loss: 0.2439 - val_accuracy: 0.5683\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 28s 353ms/step - loss: 0.2471 - accuracy: 0.5503 - val_loss: 0.2436 - val_accuracy: 0.5809\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 28s 353ms/step - loss: 0.2482 - accuracy: 0.5377 - val_loss: 0.2435 - val_accuracy: 0.5706\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2468 - accuracy: 0.5505 - val_loss: 0.2442 - val_accuracy: 0.5675\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2488 - accuracy: 0.5359 - val_loss: 0.2431 - val_accuracy: 0.5777\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2460 - accuracy: 0.5507 - val_loss: 0.2448 - val_accuracy: 0.5675\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2465 - accuracy: 0.5503 - val_loss: 0.2457 - val_accuracy: 0.5635\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 27s 333ms/step - loss: 0.2455 - accuracy: 0.5570 - val_loss: 0.2431 - val_accuracy: 0.5770\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 28s 344ms/step - loss: 0.2476 - accuracy: 0.5472 - val_loss: 0.2488 - val_accuracy: 0.5643\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 28s 354ms/step - loss: 0.2468 - accuracy: 0.5517 - val_loss: 0.2469 - val_accuracy: 0.5714\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2451 - accuracy: 0.5594 - val_loss: 0.2426 - val_accuracy: 0.5762\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2442 - accuracy: 0.5714 - val_loss: 0.2414 - val_accuracy: 0.5848\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2461 - accuracy: 0.5627 - val_loss: 0.2403 - val_accuracy: 0.5959\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2452 - accuracy: 0.5653 - val_loss: 0.2472 - val_accuracy: 0.5754\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2431 - accuracy: 0.5809 - val_loss: 0.2553 - val_accuracy: 0.5722\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2428 - accuracy: 0.5781 - val_loss: 0.2485 - val_accuracy: 0.5801\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2429 - accuracy: 0.5807 - val_loss: 0.2480 - val_accuracy: 0.5762\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2432 - accuracy: 0.5835 - val_loss: 0.2393 - val_accuracy: 0.5975\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2454 - accuracy: 0.5738 - val_loss: 0.2434 - val_accuracy: 0.5777\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2452 - accuracy: 0.5809 - val_loss: 0.2405 - val_accuracy: 0.5959\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2426 - accuracy: 0.5762 - val_loss: 0.2400 - val_accuracy: 0.5951\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2396 - accuracy: 0.6000 - val_loss: 0.2576 - val_accuracy: 0.5343\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2450 - accuracy: 0.5671 - val_loss: 0.2391 - val_accuracy: 0.6117\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2441 - accuracy: 0.5866 - val_loss: 0.2480 - val_accuracy: 0.5699\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2483 - accuracy: 0.5474 - val_loss: 0.2584 - val_accuracy: 0.4838\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2493 - accuracy: 0.5211 - val_loss: 0.2464 - val_accuracy: 0.5754\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2462 - accuracy: 0.5401 - val_loss: 0.2625 - val_accuracy: 0.5241\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2477 - accuracy: 0.5493 - val_loss: 0.2431 - val_accuracy: 0.5754\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2439 - accuracy: 0.5797 - val_loss: 0.2458 - val_accuracy: 0.5659\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2466 - accuracy: 0.5533 - val_loss: 0.2430 - val_accuracy: 0.5770\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2449 - accuracy: 0.5744 - val_loss: 0.2495 - val_accuracy: 0.5659\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2448 - accuracy: 0.5722 - val_loss: 0.2438 - val_accuracy: 0.5777\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2436 - accuracy: 0.5716 - val_loss: 0.2433 - val_accuracy: 0.5762\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2527 - accuracy: 0.5215 - val_loss: 0.2463 - val_accuracy: 0.5430\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2499 - accuracy: 0.5103 - val_loss: 0.2460 - val_accuracy: 0.5549\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2485 - accuracy: 0.5229 - val_loss: 0.2460 - val_accuracy: 0.5454\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2478 - accuracy: 0.5377 - val_loss: 0.2456 - val_accuracy: 0.5525\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2484 - accuracy: 0.5237 - val_loss: 0.2454 - val_accuracy: 0.5525\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2488 - accuracy: 0.5270 - val_loss: 0.2453 - val_accuracy: 0.5541\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2475 - accuracy: 0.5231 - val_loss: 0.2452 - val_accuracy: 0.5517\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2474 - accuracy: 0.5349 - val_loss: 0.2451 - val_accuracy: 0.5604\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2478 - accuracy: 0.5316 - val_loss: 0.2454 - val_accuracy: 0.5541\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2477 - accuracy: 0.5339 - val_loss: 0.2458 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2488 - accuracy: 0.5227 - val_loss: 0.2447 - val_accuracy: 0.5549\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2478 - accuracy: 0.5302 - val_loss: 0.2445 - val_accuracy: 0.5580\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2471 - accuracy: 0.5367 - val_loss: 0.2460 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 28s 351ms/step - loss: 0.2474 - accuracy: 0.5361 - val_loss: 0.2443 - val_accuracy: 0.5596\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2463 - accuracy: 0.5412 - val_loss: 0.2448 - val_accuracy: 0.5525\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2466 - accuracy: 0.5397 - val_loss: 0.2434 - val_accuracy: 0.5588\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2460 - accuracy: 0.5562 - val_loss: 0.2411 - val_accuracy: 0.5825\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2475 - accuracy: 0.5468 - val_loss: 0.2473 - val_accuracy: 0.5406\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2489 - accuracy: 0.5170 - val_loss: 0.2466 - val_accuracy: 0.5596\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2489 - accuracy: 0.5191 - val_loss: 0.2458 - val_accuracy: 0.5643\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2480 - accuracy: 0.5331 - val_loss: 0.2444 - val_accuracy: 0.5699\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2453 - accuracy: 0.5456 - val_loss: 0.2443 - val_accuracy: 0.5714\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2434 - accuracy: 0.5693 - val_loss: 0.2436 - val_accuracy: 0.5817\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2411 - accuracy: 0.5910 - val_loss: 0.2395 - val_accuracy: 0.5991\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2418 - accuracy: 0.5880 - val_loss: 0.2432 - val_accuracy: 0.5777\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2482 - accuracy: 0.5481 - val_loss: 0.2445 - val_accuracy: 0.5572\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 31s 388ms/step - loss: 0.2460 - accuracy: 0.5377 - val_loss: 0.2447 - val_accuracy: 0.5651\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 31s 390ms/step - loss: 0.2459 - accuracy: 0.5479 - val_loss: 0.2447 - val_accuracy: 0.5580\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 29s 363ms/step - loss: 0.2463 - accuracy: 0.5385 - val_loss: 0.2438 - val_accuracy: 0.5572\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2440 - accuracy: 0.5572 - val_loss: 0.2439 - val_accuracy: 0.5675\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2509 - accuracy: 0.5495 - val_loss: 0.2595 - val_accuracy: 0.5225\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 32s 396ms/step - loss: 0.2520 - accuracy: 0.5037 - val_loss: 0.2489 - val_accuracy: 0.5446\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2491 - accuracy: 0.5205 - val_loss: 0.2490 - val_accuracy: 0.5580\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2489 - accuracy: 0.5195 - val_loss: 0.2488 - val_accuracy: 0.5470\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2497 - accuracy: 0.5132 - val_loss: 0.2484 - val_accuracy: 0.5367\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2504 - accuracy: 0.5124 - val_loss: 0.2496 - val_accuracy: 0.4783\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2506 - accuracy: 0.5101 - val_loss: 0.2487 - val_accuracy: 0.5462\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2509 - accuracy: 0.5130 - val_loss: 0.2491 - val_accuracy: 0.4783\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2493 - accuracy: 0.5207 - val_loss: 0.2484 - val_accuracy: 0.5446\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2497 - accuracy: 0.5144 - val_loss: 0.2482 - val_accuracy: 0.5383\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2502 - accuracy: 0.5099 - val_loss: 0.2483 - val_accuracy: 0.5438\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2496 - accuracy: 0.5124 - val_loss: 0.2481 - val_accuracy: 0.5422\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2494 - accuracy: 0.5160 - val_loss: 0.2482 - val_accuracy: 0.5462\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2498 - accuracy: 0.5136 - val_loss: 0.2490 - val_accuracy: 0.4791\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2495 - accuracy: 0.5140 - val_loss: 0.2489 - val_accuracy: 0.4791\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2493 - accuracy: 0.5227 - val_loss: 0.2479 - val_accuracy: 0.5430\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2495 - accuracy: 0.5132 - val_loss: 0.2484 - val_accuracy: 0.5438\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2505 - accuracy: 0.5081 - val_loss: 0.2480 - val_accuracy: 0.5462\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 28s 347ms/step - loss: 0.2492 - accuracy: 0.5079 - val_loss: 0.2479 - val_accuracy: 0.5430\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2486 - accuracy: 0.5195 - val_loss: 0.2483 - val_accuracy: 0.5556\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2486 - accuracy: 0.5284 - val_loss: 0.2479 - val_accuracy: 0.5430\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2490 - accuracy: 0.5187 - val_loss: 0.2482 - val_accuracy: 0.5422\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2490 - accuracy: 0.5174 - val_loss: 0.2479 - val_accuracy: 0.5422\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2490 - accuracy: 0.5158 - val_loss: 0.2477 - val_accuracy: 0.5422\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 28s 349ms/step - loss: 0.2484 - accuracy: 0.5290 - val_loss: 0.2476 - val_accuracy: 0.5422\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 28s 348ms/step - loss: 0.2495 - accuracy: 0.5114 - val_loss: 0.2476 - val_accuracy: 0.5414\n"
     ]
    }
   ],
   "source": [
    "history = rnn_model.fit(X_train_pad, y_train, epochs=200, batch_size=64, \n",
    "                        validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.14%\n"
     ]
    }
   ],
   "source": [
    "pred_y = rnn_model.predict_classes(X_test_pad)\n",
    "score=accuracy_score(y_test,pred_y)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 78, 533],\n",
       "       [ 48, 608]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 512, 64)           5606208   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 512, 256)          82176     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 256, 512)          655872    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 128, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 128, 768)          1966848   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 64, 768)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64, 128)           459264    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 8,902,081\n",
      "Trainable params: 8,902,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_lstm_model = Sequential()\n",
    "conv_lstm_model.add(Embedding(input_dim=vocab_size+1, output_dim=output_dim, input_length=laenge_pads))\n",
    "conv_lstm_model.add(Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'))\n",
    "conv_lstm_model.add(MaxPooling1D(pool_size=2))\n",
    "conv_lstm_model.add(Conv1D(filters=512, kernel_size=5, padding='same', activation='relu'))\n",
    "conv_lstm_model.add(MaxPooling1D(pool_size=2))\n",
    "conv_lstm_model.add(Conv1D(filters=768, kernel_size=5, padding='same', activation='relu'))\n",
    "conv_lstm_model.add(MaxPooling1D(pool_size=2))\n",
    "conv_lstm_model.add(LSTM(128, return_sequences=True))\n",
    "conv_lstm_model.add(Dropout(0.1))\n",
    "conv_lstm_model.add(LSTM(128))\n",
    "conv_lstm_model.add(Dropout(0.1))\n",
    "conv_lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv_lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "conv_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 213s 3s/step - loss: 0.0652 - accuracy: 0.9797 - val_loss: 0.2728 - val_accuracy: 0.9227\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 218s 3s/step - loss: 0.0364 - accuracy: 0.9907 - val_loss: 0.3311 - val_accuracy: 0.9227\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 218s 3s/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.2811 - val_accuracy: 0.9305\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 220s 3s/step - loss: 0.0370 - accuracy: 0.9899 - val_loss: 0.4477 - val_accuracy: 0.8429\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 222s 3s/step - loss: 0.0167 - accuracy: 0.9970 - val_loss: 0.3914 - val_accuracy: 0.9124\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 223s 3s/step - loss: 0.1163 - accuracy: 0.9670 - val_loss: 0.4311 - val_accuracy: 0.8493\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 222s 3s/step - loss: 0.0868 - accuracy: 0.9773 - val_loss: 0.2982 - val_accuracy: 0.9187\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 224s 3s/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.2946 - val_accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 227s 3s/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.3464 - val_accuracy: 0.9203\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 246s 3s/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.3674 - val_accuracy: 0.9171\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 225s 3s/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.3296 - val_accuracy: 0.9195\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 216s 3s/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.3634 - val_accuracy: 0.9195\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 212s 3s/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.4319 - val_accuracy: 0.9203\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 215s 3s/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.4450 - val_accuracy: 0.9179\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 221s 3s/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.4452 - val_accuracy: 0.9195\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 261s 3s/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.4460 - val_accuracy: 0.9155\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 226s 3s/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.4475 - val_accuracy: 0.9155\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 238s 3s/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.4562 - val_accuracy: 0.9140\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 236s 3s/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.4589 - val_accuracy: 0.9132\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 229s 3s/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.4587 - val_accuracy: 0.9132\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 230s 3s/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.5429 - val_accuracy: 0.9108\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 218s 3s/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.5616 - val_accuracy: 0.9124\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 206s 3s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5608 - val_accuracy: 0.9116\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 213s 3s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.5728 - val_accuracy: 0.9116\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 187s 2s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5672 - val_accuracy: 0.9116\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 189s 2s/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.5717 - val_accuracy: 0.9116\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 191s 2s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5821 - val_accuracy: 0.9116\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 194s 2s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.5811 - val_accuracy: 0.9108\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 225s 3s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.6018 - val_accuracy: 0.9108\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 213s 3s/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.6010 - val_accuracy: 0.9108\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 247s 3s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5662 - val_accuracy: 0.9116\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 225s 3s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.5697 - val_accuracy: 0.9124\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 248s 3s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.5815 - val_accuracy: 0.9124\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 234s 3s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5814 - val_accuracy: 0.9124\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 259s 3s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.5945 - val_accuracy: 0.9132\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 250s 3s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5665 - val_accuracy: 0.9140\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 267s 3s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.5975 - val_accuracy: 0.9140\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 260s 3s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5897 - val_accuracy: 0.9140\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 251s 3s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.6189 - val_accuracy: 0.9148\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 243s 3s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.6374 - val_accuracy: 0.9148\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 218s 3s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.6393 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 309s 4s/step - loss: 1.5559e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.9092\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 326s 4s/step - loss: 8.0913e-05 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.9092\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 331s 4s/step - loss: 5.8490e-05 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.9092\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 328s 4s/step - loss: 4.5490e-05 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.9092\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 331s 4s/step - loss: 3.7726e-05 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.9092\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 336s 4s/step - loss: 3.0810e-05 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.9092\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 338s 4s/step - loss: 2.7664e-05 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.9084\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 332s 4s/step - loss: 2.4899e-05 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.9084\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 337s 4s/step - loss: 2.2339e-05 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.9084\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 340s 4s/step - loss: 2.0323e-05 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.9092\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 335s 4s/step - loss: 1.9054e-05 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.9092\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 347s 4s/step - loss: 1.7535e-05 - accuracy: 1.0000 - val_loss: 0.7750 - val_accuracy: 0.9084\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 312s 4s/step - loss: 1.5847e-05 - accuracy: 1.0000 - val_loss: 0.7797 - val_accuracy: 0.9084\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 238s 3s/step - loss: 1.4739e-05 - accuracy: 1.0000 - val_loss: 0.7846 - val_accuracy: 0.9084\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 240s 3s/step - loss: 1.3922e-05 - accuracy: 1.0000 - val_loss: 0.7894 - val_accuracy: 0.9077\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 224s 3s/step - loss: 1.2942e-05 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 0.9077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "80/80 [==============================] - 271s 3s/step - loss: 1.2301e-05 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.9084\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 231s 3s/step - loss: 1.1592e-05 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.9084\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 250s 3s/step - loss: 1.0847e-05 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.9092\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 203s 3s/step - loss: 1.0132e-05 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.9092\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 195s 2s/step - loss: 9.6370e-06 - accuracy: 1.0000 - val_loss: 0.8183 - val_accuracy: 0.9084\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 197s 2s/step - loss: 9.2589e-06 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.9092\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 194s 2s/step - loss: 8.5694e-06 - accuracy: 1.0000 - val_loss: 0.8291 - val_accuracy: 0.9100\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 194s 2s/step - loss: 8.0383e-06 - accuracy: 1.0000 - val_loss: 0.8342 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 194s 2s/step - loss: 7.6814e-06 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.9100\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 197s 2s/step - loss: 7.1448e-06 - accuracy: 1.0000 - val_loss: 0.8434 - val_accuracy: 0.9108\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 195s 2s/step - loss: 6.9808e-06 - accuracy: 1.0000 - val_loss: 0.8482 - val_accuracy: 0.9108\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 193s 2s/step - loss: 6.5392e-06 - accuracy: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.9108\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 196s 2s/step - loss: 6.1866e-06 - accuracy: 1.0000 - val_loss: 0.8567 - val_accuracy: 0.9108\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 194s 2s/step - loss: 5.9558e-06 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.9108\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 195s 2s/step - loss: 5.7542e-06 - accuracy: 1.0000 - val_loss: 0.8629 - val_accuracy: 0.9108\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 192s 2s/step - loss: 5.5025e-06 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.9108\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 191s 2s/step - loss: 5.2358e-06 - accuracy: 1.0000 - val_loss: 0.8692 - val_accuracy: 0.9108\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 192s 2s/step - loss: 4.9834e-06 - accuracy: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.9108\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 193s 2s/step - loss: 4.7258e-06 - accuracy: 1.0000 - val_loss: 0.8754 - val_accuracy: 0.9108\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 194s 2s/step - loss: 4.5170e-06 - accuracy: 1.0000 - val_loss: 0.8785 - val_accuracy: 0.9108\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 193s 2s/step - loss: 4.2427e-06 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.9108\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 193s 2s/step - loss: 4.1014e-06 - accuracy: 1.0000 - val_loss: 0.8840 - val_accuracy: 0.9108\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 194s 2s/step - loss: 3.9421e-06 - accuracy: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.9108\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 193s 2s/step - loss: 3.8920e-06 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.9108\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 196s 2s/step - loss: 3.6089e-06 - accuracy: 1.0000 - val_loss: 0.8935 - val_accuracy: 0.9108\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 207s 3s/step - loss: 3.4059e-06 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.9116\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 232s 3s/step - loss: 3.2830e-06 - accuracy: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.9116\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 236s 3s/step - loss: 3.1540e-06 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.9116\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 231s 3s/step - loss: 3.0239e-06 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.9116\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 224s 3s/step - loss: 2.9031e-06 - accuracy: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.9124\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 216s 3s/step - loss: 2.7527e-06 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.9124\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 220s 3s/step - loss: 2.5660e-06 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.9124\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 224s 3s/step - loss: 2.5236e-06 - accuracy: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.9116\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 220s 3s/step - loss: 2.3742e-06 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.9124\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 209s 3s/step - loss: 2.3297e-06 - accuracy: 1.0000 - val_loss: 0.9281 - val_accuracy: 0.9116\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 206s 3s/step - loss: 2.1590e-06 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.9116\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 192s 2s/step - loss: 2.0590e-06 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.9116\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 200s 3s/step - loss: 2.0307e-06 - accuracy: 1.0000 - val_loss: 0.9392 - val_accuracy: 0.9116\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 193s 2s/step - loss: 1.8998e-06 - accuracy: 1.0000 - val_loss: 0.9427 - val_accuracy: 0.9100\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 196s 2s/step - loss: 1.8339e-06 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.9092\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 195s 2s/step - loss: 1.7542e-06 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.9092\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 195s 2s/step - loss: 1.6728e-06 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.9092\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 195s 2s/step - loss: 1.5829e-06 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.9092\n"
     ]
    }
   ],
   "source": [
    "history = conv_lstm_model.fit(X_train_pad, y_train, epochs=100, batch_size=64, \n",
    "                        validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.92%\n"
     ]
    }
   ],
   "source": [
    "pred_y = conv_lstm_model.predict_classes(X_test_pad)\n",
    "score=accuracy_score(y_test,pred_y)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[551,  60],\n",
       "       [ 55, 601]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
